#!/usr/bin/env nextflow
/*
========================================================================================
                         bi-geneset-enrichment-analysis-nf
========================================================================================
 bi-geneset-enrichment-analysis-nf Analysis Pipeline.
 #### Homepage / Documentation
 https://github.com/bi-geneset-enrichment-analysis-nf
----------------------------------------------------------------------------------------
*/

nextflow.enable.dsl=2

def helpMessage() {
    // TODO nf-core: Add to this help message with new command line parameters
    log.info nfcoreHeader()
    log.info"""

    Usage:

    The typical command for running the pipeline is as follows:

    nextflow run bi-geneset-enrichment-analysis-nf --reads '*_R{1,2}.fastq.gz' -profile docker

    Mandatory arguments:
      --reads [file]                Path to input data (must be surrounded with quotes)
      -profile [str]                Configuration profile to use. Can use multiple (comma separated)
                                    Available: conda, docker, singularity, test, awsbatch, <institute> and more

    Options:
      --genome [str]                  Name of iGenomes reference
      --single_end [bool]             Specifies that the input is single-end reads

    References                        If not specified in the configuration file or you wish to overwrite any of the references
      --fasta [file]                  Path to fasta reference

    Other options:
      --outdir [file]                 The output directory where the results will be saved
      --email [email]                 Set this parameter to your e-mail address to get a summary e-mail with details of the run sent to you when the workflow exits
      --email_on_fail [email]         Same as --email, except only send mail if the workflow is not successful
      --max_multiqc_email_size [str]  Theshold size for MultiQC report to be attached in notification email. If file generated by pipeline exceeds the threshold, it will not be attached (Default: 25MB)
      -name [str]                     Name for the pipeline run. If not specified, Nextflow will automatically generate a random mnemonic
    """.stripIndent()
}



//--------------------------------------------------------------------------

// Header log info
def summary = [:]

/*
 * Main process starts here
 */

// // this process is just for meaintain a proper channel by diverting reference panel to plink
process preprocess_plink {

    input:
    file bed
    file bim
    file fam

    output:
    tuple path("${bed}"), path("${bim}"), path("${fam}"), emit: plink_direct

    script:
    """
    echo "No Modifications to files. This step used for staging the files to make a unified nextflow channel for next step."
    """
}

// this process is just for meaintain a proper channel by diverting reference panel to plink 
process preprocess_ref_panel {

    input:
    file bed
    file bim
    file fam

    output:
    tuple path("${bed}"), path("${bim}"), path("${fam}"), emit: plink_ref_panel

    script:
    """
    echo "No Modifications to files. This step used for staging the files to make a unified nextflow channel for next step."
    """
}

process extract_snp_p_from_sumstats {

    input:
    path gwas_vcf

    output:
    path('snp_p.tsv'), emit: snp_p_txt

    script:
    """
    echo "SNP\tP" > snp_p.tsv
    bcftools query -f'[%SNP]\t[%P]\n' $gwas_vcf >> snp_p.tsv
    """
}

process preprocessing_vcf {
    publishDir "${params.outdir}/processed_files", mode: 'copy'
    
    input:
    path vcfs
    path vcf_file

    output:
    path 'merged.vcf', emit: vcf_plink
    path 'sample.phe', emit: data

    script:
    """
    # iterate through urls in csv replacing s3 path with the local one
    urls="\$(tail -n+2 $vcf_file | awk -F',' '{print \$2}')"
    for url in \$(echo \$urls); do
        vcf="\${url##*/}"
        sed -i -e "s~\$url~\$vcf~g" $vcf_file
    done
    # bgzip uncompressed vcfs
    for vcf in \$(tail -n+2 $vcf_file | awk -F',' '{print \$2}'); do
        if [ \${vcf: -4} == ".vcf" ]; then
                bgzip -c \$vcf > \${vcf}.gz
                sed -i "s/\$vcf/\${vcf}.gz/g" $vcf_file 
        fi
    done
    # remove any prexisting columns for sex 
    if grep -Fq "SEX" $vcf_file; then
        awk -F, -v OFS=, 'NR==1{for (i=1;i<=NF;i++)if (\$i=="SEX"){n=i-1;m=NF-(i==NF)}} {for(i=1;i<=NF;i+=1+(i==n))printf "%s%s",\$i,i==m?ORS:OFS}' $vcf_file > tmp.csv && mv tmp.csv $vcf_file
    fi
    # determine sex of each individual from VCF file & add to csv file
    echo 'SEX' > sex.txt
    for vcf in \$(tail -n+2 $vcf_file | awk -F',' '{print \$2}'); do
        bcftools index -f \$vcf
        SEX="\$(bcftools plugin vcf2sex \$vcf)"
        if [[ \$SEX == *M ]]; then
                echo "1" >> sex.txt
        elif [ \$SEX == *F ]]; then
                echo "2" >> sex.txt
        fi
    done
    # make fam file & merge vcfs
    paste -d, sex.txt $vcf_file > tmp.csv && mv tmp.csv $vcf_file
    make_fam2.py $vcf_file
    vcfs=\$(tail -n+2 $vcf_file | awk -F',' '{print \$3}')
    bcftools merge --force-samples \$vcfs > merged.vcf
    """
}

// run plink on given vcf files
process plink {
    publishDir "${params.outdir}/plink", mode: 'copy'
    
    input:
    path vcf
    path fam

    output:
    tuple path('*.bed'), path('*.bim'), path('*.fam'), emit: plink_undirect

    script:
    """
    sed '1d' $fam > tmpfile; mv tmpfile $fam
    # remove contigs eg GL000229.1 to prevent errors
    sed -i '/^GL/ d' $vcf
    plink --vcf $vcf --make-bed
    rm plink.fam
    mv $fam plink.fam
    """
}

// MAGMA stats here
process magma_annotation {
    publishDir "${params.outdir}/magma", mode: 'copy'
    
    input:
    tuple file(bed), file(bim), file(fam)
    file(gene_loc_file)
    file(snp_subset_file)

    output:
    path('magma_out.genes.annot'), emit: magma_anot
    path('magma_out.genes.annot.log')

    script:
    if (params.snp_subset) annotate_filter='filter=snpsubset.bim' else annotate_filter=''
    """
    mv $snp_subset_file snpsubset.bim
    magma --annotate \
        window=${params.window} ${annotate_filter} \
        --snp-loc ${bim} \
        --gene-loc ${gene_loc_file} \
        --out magma_out
    mv magma_out.log magma_out.genes.annot.log
    """
}

process magma_gene_analysis {
    publishDir "${params.outdir}/magma", mode: 'copy'
    
    input:
    tuple file(bed), file(bim), file(fam)
    file(magma_anot)
    file(snp_p_file)
    file(ref_panel_synonyms)

    output:
    path('magma_out.genes.raw'), emit: genes_raw
    path('magma_out.genes.out')
    path('magma_out.genes.out.log')

    script:
    // optional params for gene analysis
    if (params.summary_stats) pval = "--pval snp_p.tsv N=" + params.sample_size else pval=''
    if(params.seed) seed = "--seed " + params.seed else seed=''
    if(params.snp_max_maf) snp_max_maf = "snp-max-maf=" + params.snp_max_maf else snp_max_maf=''
    if(params.snp_max_mac) snp_max_mac = "snp-max-mac=" + params.snp_max_mac else snp_max_mac=''
    if(params.burden) burden = "--burden " + params.burden else burden = ''
    if(params.big_data) big_data = "--big-data" + params.big_data else big_data=''
    if(params.gene_model) gene_model = "--gene-model " + params.gene_model else gene_model=''
    // exceptions with summary stats file
    if (params.summary_stats && params.gene_model == "linreg") println "Workflow Error: '--gene_model linreg' can't be used with summary stats file" exit 0
    """
    # change the names. It should be equal for all (for the purpose of upload timestamp)
    mv ${bed} plink_file.bed
    mv ${bim} plink_file.bim
    mv ${fam} plink_file.fam

    magma --bfile plink_file \
        ${pval} \
        --gene-settings \
        snp-min-maf=${params.snp_min_maf} \
        ${snp_max_maf} \
        snp-min-mac=${params.snp_min_mac} \
        ${snp_max_mac} \
        snp-max-miss=${params.snp_max_miss} \
        snp-diff=${params.snp_diff} \
        ${seed} \
        ${burden} \
        ${big_data} \
        ${gene_model} \
        --gene-annot ${magma_anot} \
        --out magma_out
    mv magma_out.log magma_out.genes.out.log
    """
}

process magma_geneset_analysis {
    publishDir "${params.outdir}/magma", mode: 'copy'
    
    input:
    file(gene_raw)
    file(set_anot)

    output:
    path('magma_out.gsa.out'), emit: geneset
    path('*.out')
    path('magma_out.gsa.out.log')

    script:
    // additional geneset settings (optional)
    if(params.gene_info) gene_info = "gene-info" else gene_info = ''
    if(params.self_contained) self_contained = "self-contained" else self_contained = ''
    if(params.alpha) alpha = "alpha=" + params.alpha else alpha=''
    """
    magma --gene-results ${gene_raw} \
        --settings outlier=${params.outlier_up},${params.outlier_down} \
        ${gene_info} \
        --model direction-sets=${params.direction_sets} \
        ${self_contained} ${alpha} \
        correct=${params.correct} \
        --set-annot ${set_anot} \
        --out magma_out
    mv magma_out.log magma_out.gsa.out.log
    """
}

// process magma_gene_property_analysis {
//     publishDir "${params.outdir}/magma", mode: 'copy'
    
//     input:
//     file(gene_raw)
//     file(cov)

//     output:
//     file('magma_out.gsa.out.cov')
//     file('magma_out.gsa.out.cov.log')

//     script:
//     """
//     magma --gene-results ${gene_raw} \
//         --out magma_out
//     mv magma_out.gsa.out magma_out.gsa.out.cov
//     mv magma_out.log magma_out.gsa.out.cov.log
//     """
// }


process results_plots {
    publishDir "${params.outdir}/magma", mode: 'copy'
    
    input:
    file(geneset)

    output:
    path('*.png'), emit: report_plot
    path('*.sorted.csv'), emit: res_sorted
    path('*.plot.csv'), emit: res_top

    script:
    """
    dot_plot.R ${geneset} ${params.pvalue_cutoff} ${params.top_n_value}
    """
}

process get_genenames {
    publishDir "${params.outdir}/magma", mode: 'copy'
    
    input:
    file(res_sorted)
    file(res_top)
    file(anot)
    file(geneset)
    file(geneloc)

    output:
    path("magma_out.gsa.out.sorted.genenames.tsv"), emit: report_table
    path('*top*.tsv')

    script:
    """
    gene_map.R ${res_sorted} ${anot} ${geneset} ${geneloc}
    gene_map.R ${res_top} ${anot} ${geneset} ${geneloc}
    """
}

/*
 * report
 */
process multiqc {
    publishDir "${params.outdir}/MultiQC", mode: 'copy'

    input:
    file (report_table)
    file (report_plot)
    
    output:
    path "multiqc_report.html", emit: multiqc_report

    script:
    """
    cp /opt/bin/* .
    Rscript -e "rmarkdown::render('report.Rmd', params = list(gsa_plot='$report_plot',gsa_result='$report_table'))"
    mv report.html multiqc_report.html
    """
}

workflow lifebitai_geneset_enrichment {
    take:
        ch_gene_loc_file
        ch_set_anot
        ch_summary_stats

    main:
        // Show help message
        if (params.help) {
            helpMessage()
            exit 0
        }
        
        ch_ref_panel_bed = Channel.fromPath(params.ref_panel_bed)
                            .ifEmpty { exit 1, "File not found: ${params.ref_panel_bed}" }

        ch_ref_panel_bim = Channel.fromPath(params.ref_panel_bim)
                            .ifEmpty { exit 1, "File not found: ${params.ref_panel_bim}" }

        ch_ref_panel_fam = Channel.fromPath(params.ref_panel_fam)
                            .ifEmpty { exit 1, "File not found: ${params.ref_panel_fam}" }

        ch_ref_panel_synonyms = Channel.fromPath(params.ref_panel_synonyms)
                                .ifEmpty { exit 1, "File not found: ${params.ref_panel_synonyms}" }

        extract_snp_p_from_sumstats(ch_summary_stats)

        ch_snp_p = extract_snp_p_from_sumstats.out.snp_p_txt
     
        preprocess_ref_panel(ch_ref_panel_bed,
                                ch_ref_panel_bim,
                                ch_ref_panel_fam)

        ch_plink = preprocess_ref_panel.out.plink_ref_panel

        //    if a subset file is provided
        if (params.snp_subset) {
            Channel.fromPath(params.snp_subset)
                .ifEmpty { exit 1, "A .bim file not found: ${params.snp_subset}" }
                .set { ch_snp_subset }
        }

        if (!params.snp_subset) {
            ch_snp_subset = ''
        }


        magma_annotation(ch_plink,
                            ch_gene_loc_file,
                            ch_snp_subset)
        

        magma_gene_analysis(ch_plink,
                            magma_annotation.out.magma_anot,
                            ch_snp_p,
                            ch_ref_panel_synonyms)
        
        magma_geneset_analysis(magma_gene_analysis.out.genes_raw,
                                ch_set_anot)
        
        results_plots(magma_geneset_analysis.out.geneset)

        get_genenames(results_plots.out.res_sorted,
                        results_plots.out.res_top,
                        magma_annotation.out.magma_anot,
                        ch_set_anot,
                        ch_gene_loc_file)
        
        multiqc(get_genenames.out.report_table,
                results_plots.out.report_plot)
        
        multiqc_report = multiqc.out.multiqc_report
    
    emit:
        multiqc_report

}

workflow{

    /*
    * SET UP CONFIGURATION VARIABLES
    */

    // Check if genome exists in the config file



    // Stage config files

    //--------------------------------------------------------------------------

    if (!params.gene_loc_file){
        exit 1, "Provide mandatory argument '--gene_loc_file'"
    } 
    if (params.gene_loc_file){
        ch_gene_loc_file = Channel.fromPath(params.gene_loc_file)
    }

    if (!params.set_anot_file) {
        exit 1, "Provide mandatory argument '--set_anot_file'"
    } 
    if (params.set_anot_file) {
        ch_set_anot = Channel.fromPath(params.set_anot_file)
    }
    // if (params.cov_file) {
    //     ch_cov = Channel.fromPath(params.cov_file)
    // }


        ch_ref_panel_bed = Channel.fromPath(params.ref_panel_bed)
                            .ifEmpty { exit 1, "File not found: ${params.ref_panel_bed}" }

        ch_ref_panel_bim = Channel.fromPath(params.ref_panel_bim)
                            .ifEmpty { exit 1, "File not found: ${params.ref_panel_bim}" }

        ch_ref_panel_fam = Channel.fromPath(params.ref_panel_fam)
                            .ifEmpty { exit 1, "File not found: ${params.ref_panel_fam}" }

        ch_ref_panel_synonyms = Channel.fromPath(params.ref_panel_synonyms)
                                .ifEmpty { exit 1, "File not found: ${params.ref_panel_synonyms}" }

    //--------------------------------------------------------------------------

    //--------------------------------------------------------------------------

    if (workflow.revision) summary['Pipeline Release'] = workflow.revision
    summary['Run Name']         =  workflow.runName
    // TODO nf-core: Report custom parameters here
    summary['Gene-Location file'] = params.gene_loc_file
    summary['set anot file'] = params.set_anot_file
    summary['Summary Stats'] = params.summary_stats
    summary['ref_panel_bed'] = params.ref_panel_bed
    summary['ref_panel_bim'] = params.ref_panel_bim
    summary['ref_panel_fam'] = params.ref_panel_fam
    summary['ref_panel_synonyms'] = params.ref_panel_synonyms
    summary['snp_subset'] = params.snp_subset
    if (workflow.containerEngine) summary['Container'] = "$workflow.containerEngine - $workflow.container"
    summary['Output dir']       = params.outdir
    summary['Launch dir']       = workflow.launchDir
    summary['Working dir']      = workflow.workDir
    summary['Script dir']       = workflow.projectDir
    summary['User']             = workflow.userName
    summary['Config Profile'] = workflow.profile
    log.info summary.collect { k,v -> "${k.padRight(18)}: $v" }.join("\n")
    log.info "-\033[2m--------------------------------------------------\033[0m-"

    ch_workflow_summary = Channel.from(summary.collect{ [it.key, it.value] })
        .map { k,v -> "<dt>$k</dt><dd><samp>${v ?: '<span style=\"color:#999999;\">N/A</a>'}</samp></dd>" }
        .reduce { a, b -> return [a, b].join("\n            ") }
        .map { x -> """
        id: 'nf-core-gwasgsa-summary'
        description: " - this information is collected when the pipeline is started."
        section_name: 'bi-geneset-enrichment-analysis-nf Workflow Summary'
        section_href: 'https://github.com/bi-geneset-enrichment-analysis-nf'
        plot_type: 'html'
        data: |
            <dl class=\"dl-horizontal\">
                $x
            </dl>
        """.stripIndent() }

    if(params.summary_stats){
        ch_summary_stats = Channel.fromPath(params.summary_stats)
        lifebitai_geneset_enrichment_vcf(
            ch_gene_loc_file,
            ch_set_anot,
            ch_summary_stats
        )
    }
}
